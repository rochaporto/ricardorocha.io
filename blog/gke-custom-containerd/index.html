<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Ricardo Rocha"><meta name=description content="Software Engineer at CERN"><meta name=generator content="Hugo 0.60.0"><title>Custom Containerd Versions in GKE Clusters</title><link rel="shortcut icon" href=https://ricardorocha.io/images/favicon.ico><link rel=stylesheet href=https://ricardorocha.io/css/style.css><link rel=stylesheet href=https://ricardorocha.io/css/highlight.css><link rel=stylesheet href=https://ricardorocha.io/css/monosocialiconsfont.css><link href=https://ricardorocha.io/index.xml rel=alternate type=application/rss+xml title="Ricardo Rocha"><meta property="og:title" content="Custom Containerd Versions in GKE Clusters"><meta property="og:description" content="Upgrade containerd on a GKE cluster"><meta property="og:type" content="article"><meta property="og:url" content="https://ricardorocha.io/blog/gke-custom-containerd/"><meta property="article:published_time" content="2020-10-25T22:00:00+00:00"><meta property="article:modified_time" content="2020-10-25T22:00:00+00:00"><meta itemprop=name content="Custom Containerd Versions in GKE Clusters"><meta itemprop=description content="Upgrade containerd on a GKE cluster"><meta itemprop=datePublished content="2020-10-25T22:00:00&#43;00:00"><meta itemprop=dateModified content="2020-10-25T22:00:00&#43;00:00"><meta itemprop=wordCount content="481"><meta itemprop=keywords content="kubernetes,gke,containerd,"><meta name=twitter:card content="summary"><meta name=twitter:title content="Custom Containerd Versions in GKE Clusters"><meta name=twitter:description content="Upgrade containerd on a GKE cluster"><meta name=twitter:site content="@https://twitter.com/ahcorporto"></head><body><nav class=main-nav><a href=https://ricardorocha.io/><span class=arrow>‚Üê</span>Home</a>
<a href=/blog/>Blog</a>
<a href=/project>Projects</a>
<a href=/talk/>Talks</a>
<a href=/story/>Stories</a>
<a href=/about/>About</a>
<a href=https://ricardorocha.io/index.xml>RSS</a></nav><section id=wrapper><article class=post><header><h1>Custom Containerd Versions in GKE Clusters</h1><h2 class=headline>October 25, 2020 - 3 min read<br><a href=https://ricardorocha.io/tags/kubernetes>kubernetes</a>
<a href=https://ricardorocha.io/tags/gke>gke</a>
<a href=https://ricardorocha.io/tags/containerd>containerd</a></h2></header><section id=post-body><p>GKE (Google Kubernetes Engine) is a strong option for managed Kubernetes
cluster deployments, backed by the Google Cloud Platform. Relying on managed
services reduces the maintenance overhead and building on features such as
auto-repair and auto-upgrade is also a plus.</p><p>In some rare cases more flexibility is required, usually involving an early or
very experimental feature in a critical component. In this case, we need a more
recent version of containerd.</p><p>The need comes from experiments with the containerd <a href=https://github.com/containerd/stargz-snapshotter>stargz remote
snapshotter</a>, a very cool
tool that dramatically improves the container startup time (especially for
large images) while reducing network usage. Being a very recent tool it
requires containerd &gt;=1.4, while GKE currently offers:</p><ul><li>non containerd node flavors still relying on Docker</li><li>a COS containerd node flavor offering containerd 1.3</li><li>an Ubuntu containerd node flavor offering containerd 1.2</li></ul><p>For this experiment we will base on the last option above - Ubuntu containerd -
and we'll upgrade the node's containerd binaries, in an aggressive way that
could break any hope of auto repair, auto upgrade or GKE support still
being possible after.</p><p>Here's how an original GKE cluster node looks like.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>kubectl get node -o wide
NAME                                              STATUS   ROLES    AGE     VERSION             INTERNAL-IP   EXTERNAL-IP    OS-IMAGE             KERNEL-VERSION   CONTAINER-RUNTIME
gke-stargz-west4-001-default-pool-8ee80358-xrjk   Ready    &lt;none&gt;   4m38s   v1.17.12-gke.1501   10.164.0.9    34.91.157.64   Ubuntu 18.04.5 LTS   5.4.0-1024-gcp   containerd://1.2.10
</code></pre></div><p>And here's the script that will very quickly break the node and bring it back
with our required containerd version.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ cat setup-ctr-14.sh
<span style=color:#75715e>#!/bin/bash</span>
set -x
set +e

<span style=color:#75715e># download / extract cri containerd 1.4</span>
rm -rf usr/ etc/ opt/ cri-containerd*
wget --quiet https://github.com/containerd/containerd/releases/download/v1.4.1/cri-containerd-cni-1.4.1-linux-amd64.tar.gz
tar zxvf cri-containerd-cni-1.4.1-linux-amd64.tar.gz

<span style=color:#75715e># stop the kubelet and delete all running containers</span>
sudo systemctl stop kubelet <span style=color:#f92672>||</span> true
sudo crictl ps | grep Runnin | awk <span style=color:#e6db74>&#39;{print $1}&#39;</span> | xargs sudo crictl rm -f <span style=color:#f92672>||</span> true

<span style=color:#75715e># stop containerd and copy the new binaries in place</span>
sudo systemctl stop containerd <span style=color:#f92672>||</span> true
sudo ps auxw | grep containerd | awk <span style=color:#e6db74>&#39;{print $2}&#39;</span> | xargs sudo kill -9 <span style=color:#f92672>||</span> true
sudo cp usr/local/bin/* /usr/bin
sudo rm -rf /opt/cni <span style=color:#f92672>&amp;&amp;</span> sudo cp -R opt/cni /opt/

<span style=color:#75715e># restart containerd and the kubelet (the wait between comes from trial and error)</span>
sudo systemctl start containerd
sleep <span style=color:#ae81ff>10</span>
sudo systemctl start kubelet
</code></pre></div><p>And that's it, go ahead and run this on all your nodes.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>export ZONE<span style=color:#f92672>=</span>europe-west4-a
export PROJECT<span style=color:#f92672>=</span>YOURPROJECT
<span style=color:#66d9ef>for</span> n in <span style=color:#66d9ef>$(</span>kubectl get node -o custom-columns<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;DATA:metadata.name&#39;</span> | grep gke<span style=color:#66d9ef>)</span>; <span style=color:#66d9ef>do</span>
	scp -o StrictHostKeyChecking<span style=color:#f92672>=</span>no setup-ctr-14.sh <span style=color:#e6db74>${</span>n<span style=color:#e6db74>}</span>.<span style=color:#e6db74>${</span>ZONE<span style=color:#e6db74>}</span>.<span style=color:#e6db74>${</span>PROJECT<span style=color:#e6db74>}</span>:~/
	ssh -o StrictHostKeyChecking<span style=color:#f92672>=</span>no <span style=color:#e6db74>${</span>n<span style=color:#e6db74>}</span>.<span style=color:#e6db74>${</span>ZONE<span style=color:#e6db74>}</span>.<span style=color:#e6db74>${</span>PROJECT<span style=color:#e6db74>}</span> ~/setup-ctr-14.sh
<span style=color:#66d9ef>done</span>
</code></pre></div><p>You should almost immediately see the result.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>kubectl get node -o wide
NAME                                              STATUS   ROLES    AGE     VERSION             INTERNAL-IP   EXTERNAL-IP    OS-IMAGE             KERNEL-VERSION   CONTAINER-RUNTIME
gke-stargz-west4-001-default-pool-8ee80358-xrjk   Ready    &lt;none&gt;   7m52s   v1.17.12-gke.1501   10.164.0.9    34.91.157.64   Ubuntu 18.04.5 LTS   5.4.0-1024-gcp   containerd://1.4.1
</code></pre></div><p>Kubernetes is doing the real magic, with the node containers
being recreated as soon as the kubelet reports back - this is really a proof of
Kubernetes's resilience to failure, as we pretty much kill everything running
on the node.</p></section></article><aside><header><strong>Related Content</strong></header><br><ul id=post-list class="archive readmore"><li><a href=/blog/prometheus-metrics-mtail/>Blog: Generating Prometheus Metrics from Application Logs<aside class=dates>December 16, 2020, 4 min reading time</aside></a><br>Using mtail and sidecar containers to expose metrics</li><li><a href=/blog/teleworking-setup-novpn/>Blog: A VPN-less Teleworking Setup<aside class=dates>November 16, 2020, 2 min reading time</aside></a><br>Making work from home simpler when VPNs are not an option</li><li><a href=/blog/prometheus-metrics-in-pandas/>Blog: Analysing Prometheus Metrics in Pandas<aside class=dates>November 13, 2020, 4 min reading time</aside></a><br>An example for GPU workload metrics</li></ul></aside><footer id=footer><div id=social><a class=symbol href=https://github.com/rochaporto>roundedgithub</a>
<a class=symbol href=https://www.linkedin.com/in/ricardo-rocha-739aa718>roundedlinkedin</a>
<a class=symbol href=https://twitter.com/ahcorporto>roundedtwitterbird</a></div><p class=small>Think Positive, Flaps Negative<br>@ Copyright 2021 Ricardo Rocha, Built with <a href=http://gohugo.io>Hugo</a></p></footer></section><script src=//ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js></script><script src=https://ricardorocha.io/js/main.js></script><script src=https://ricardorocha.io/js/highlight.js></script><script>hljs.initHighlightingOnLoad();</script></body></html>